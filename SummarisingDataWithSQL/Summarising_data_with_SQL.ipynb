{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Querying and Summarising with SQL\n",
    "\n",
    "This exercise is about working with an existing database.\n",
    "\n",
    "The following assumes a bit of background on SQL, in particular on its core commands \n",
    "to create new tables and to retrieve data:\n",
    "\n",
    " SQL Command   |  Meaning\n",
    " --------------|------------\n",
    " SELECT COUNT(\\*) FROM *T*   | count how many tuples are stored in table *T*\n",
    " SELECT \\* FROM *T*          | list the content of table *T*\n",
    " SELECT \\* FROM *T* LIMIT *n* | only list  *n* tuples from a table\n",
    " SELECT \\* FROM *T* ORDER BY *a* | order the result by attribute *a* (in ascending order; add DESC for descending order)\n",
    "\n",
    "You can learn more background on these SQL commands in the [Python&SQL tutorial part in Grok][1] (Section 16 onwards).\n",
    "\n",
    "  [1]: https://groklearning.com/course/usyd-comp5310-2016-s1/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL: Joins\n",
    "\n",
    "If you need to combine data from multiple tables, you can **join** those as follows.\n",
    "\n",
    "**Example:** We would like to find out the details on when and where the temperature values were recorded.\n",
    "\n",
    "We first can have a look at the <tt>Measurement</tt> table:\n",
    "<pre>\n",
    "SELECT station, value, date\n",
    "  FROM Measurement\n",
    " WHERE sensor = 'temp'; \n",
    "</pre>\n",
    "\n",
    "If you execute the SQL query above, you see that the temperature was measured at two different stations over the course of two years. But we cannot see the station  details directly, just an internal ID that refers to the <tt>Station</tt> table.\n",
    "\n",
    "You could now look into that table too with a second query and check for the two different stations mentioned above - but that is tedious and error prone...\n",
    "<pre>\n",
    "SELECT * FROM Station;\n",
    "</pre>\n",
    "\n",
    "The correct way is to use this *foreign key* attribute <tt>station</tt> from the <tt>Measurment</tt> table to **join** both the <tt>Measurment</tt> and the <tt>station</tt> tables and retreive the macthing values in just one query:\n",
    "\n",
    "<pre>\n",
    "SELECT  value, date, SiteName\n",
    "  FROM Measurement JOIN station USING (station)\n",
    "  WHERE sensor = 'temp';\n",
    "</pre>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with DATE values \n",
    "\n",
    "For most data types in SQL - notably integers, strings, floating point numbers - the standard comparison and numerical operations apply.\n",
    "\n",
    "The handling of <tt>DATE</tt> is a bit delicate though. You can compare them using date strings, but the standard date format can be configured differently in database systems than you expect (eg. 'yyyy-mm-dd' vs. 'mm/dd/yyyy' etc), so that these kind of codes are difficult to port.\n",
    "\n",
    "<pre>\n",
    "SELECT *\n",
    "  FROM Measurement\n",
    " WHERE date = '2005-04-29';\n",
    "SELECT *\n",
    "  FROM Measurement\n",
    " WHERE date = '29/04/2005'; \n",
    "</pre>\n",
    "\n",
    "The SQL **EXTRACT()** function provides a convenient way to access any part of a date value. For example, **extract(year from datevar)** allows to extract the year component of a given date cariable *datevar*.\n",
    "For a full description of all components available to *extract()*, see [the PostgreSQL online documentation][1].\n",
    "\n",
    "**Example:**\n",
    "<pre>\n",
    "SELECT *\n",
    "  FROM Measurement\n",
    " WHERE extract(year from date) = 2004;\n",
    "</pre>\n",
    "\n",
    " [1]:[http://www.postgresql.org/docs/current/static/functions-datetime.html#FUNCTIONS-DATETIME-EXTRACT]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL: Aggregation Functions\n",
    "\n",
    "SQL supports multiple aggregation functions.\n",
    "\n",
    " SQL Aggregate Function | Meaning\n",
    " --- | ---\n",
    " COUNT(\\*)   | count all tuples in a table\n",
    " COUNT(attr) | count the tuples with a non-NULL value in attr\n",
    " MIN(attr)   | determine the minimum value of attr (ignores NULL)\n",
    " MAX(attr)   | determine the maximum value of attr (ignores NULL)\n",
    " AVG(attr)   | determine the average value of numeric attr (arithmetic mean) (ignores NULL)\n",
    " SUM(attr)   | calculates the sum of a numeric attr (ignores NULL)\n",
    "\n",
    "\n",
    "\n",
    "Try some out:\n",
    "\n",
    "\n",
    "**Question:** In which range (minimum to maximum) did the temp sensor do the measurements?\n",
    "<pre>\n",
    "SELECT MIN(value), MAX(value) FROM Measurement WHERE sensor = 'temp';  \n",
    "</pre>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL Statistical Aggregates\n",
    "\n",
    "SQL also supports some statistical aggregates. The syntax is a bit more complex, as they work on ordered sets. This order has to be first specified with an *WITHIN GROUP* clause in SQL so that aggregates like 'Median' or 'Percentile' make sense.\n",
    "\n",
    "Statistics Aggregate | Meaning\n",
    "---|---\n",
    "MODE()  WITHIN GROUP (ORDER BY *attr*) |  mode function over *attr*\n",
    "PERCENTILE_DISC(0.5) WITHIN GROUP (ORDER BY *attr*) | median of the *attr* values\n",
    "PERCENTILE_DISC(*p*) WITHIN GROUP (ORDER BY *attr*) | *p* percentile of the *attr* values\n",
    "\n",
    "**Example:** Statistical analysis over the temperature values of *all* measurements.\n",
    "\n",
    "<pre>\n",
    "SELECT COUNT(value),\n",
    "       MIN(value),\n",
    "       Max(value), \n",
    "       MAX(value) - MIN(value)                           AS Range, \n",
    "       AVG(value)                                            AS Mean,\n",
    "       MODE()  WITHIN GROUP (ORDER BY value)                 AS Mode, \n",
    "       PERCENTILE_DISC(0.5) WITHIN GROUP (ORDER BY value)    AS Median,\n",
    "       PERCENTILE_DISC(0.25) WITHIN GROUP (ORDER BY value)   AS Percentile25, \n",
    "       PERCENTILE_DISC(0.75) WITHIN GROUP (ORDER BY value)   AS Percentile75,\n",
    "       PERCENTILE_DISC(0.75) WITHIN GROUP (ORDER BY value)\n",
    "       - PERCENTILE_DISC(0.25) WITHIN GROUP (ORDER BY value) AS IQR \n",
    "  FROM Measurement WHERE sensor='temp' and extract (year from date) = '2004';\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE 1: Data Gathering from an SQL Database\n",
    "\n",
    "In this next exercise, we will be looking into how to retrieve data from an existing SQL database into a Python program for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Data Loading and Exploring for Water Database\n",
    "\n",
    "### Step1: Loading Water DB\n",
    "\n",
    "The first step is to make sure that the water data set is fully loaded into our PostgreSQL database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: DB Connection and Query Execution\n",
    "\n",
    "In the first step, we are repeating the basic database connection phase from the previous exercise and we execute a simple SQL query on that database.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import json\n",
    "\n",
    "f = open('Credentials.json')\n",
    "db_conn_dict = json.load(f)\n",
    "YOUR_DBNAME =  db_conn_dict['database']\n",
    "YOUR_USERNAME = db_conn_dict['user']\n",
    "YOUR_PW = db_conn_dict['password']\n",
    "\n",
    "def pgconnect():\n",
    "  \n",
    "    try: \n",
    "        conn = psycopg2.connect(host='localhost',\n",
    "                                database=YOUR_DBNAME,\n",
    "                                user=YOUR_USERNAME, \n",
    "                                password=YOUR_PW)\n",
    "        print('connected')\n",
    "    except Exception as e:\n",
    "        print(\"unable to connect to the database\")\n",
    "        print(e)\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2.extras\n",
    "\n",
    "def pgquery( conn, sqlcmd, args, silent=False, returntype='tuple'):\n",
    "   \"\"\" utility function to execute some SQL query statement\n",
    "       it can take optional arguments (as a dictionary) to fill in for placeholder in the SQL\n",
    "       will return the complete query result as return value - or in case of error: None\n",
    "       error and transaction handling built-in (by using the 'with' clauses) \"\"\"\n",
    "   retval = None\n",
    "   with conn:\n",
    "      cursortype = None if returntype != 'dict' else psycopg2.extras.RealDictCursor     \n",
    "      with conn.cursor(cursor_factory=cursortype) as cur:\n",
    "         try:\n",
    "            if args is None:\n",
    "                cur.execute(sqlcmd)\n",
    "            else:\n",
    "                cur.execute(sqlcmd, args)\n",
    "            retval = cur.fetchall() # we use fetchall() as we expect only _small_ query results\n",
    "         except Exception as e:\n",
    "            if e.pgcode != None and not(silent):\n",
    "                print(\"db read error: \")\n",
    "                print(e)\n",
    "   return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "# connect to your database\n",
    "conn = pgconnect()\n",
    "    \n",
    "# prepare SQL statement\n",
    "query_stmt = \"SELECT * FROM Sensor\"\n",
    "\n",
    "# execute query and print result\n",
    "query_result = pgquery (conn, query_stmt, None)\n",
    "print(query_stmt)\n",
    "pprint.pprint(query_result)\n",
    "\n",
    "# prepare another SQL statement including placeholders\n",
    "query_stmt = \"SELECT * FROM Measurement WHERE date=%(date)s limit 3\"\n",
    "\n",
    "# define the 'date' parameter, execute query+parameters. and print result\n",
    "param = {'date' : '29/04/2005'}\n",
    "query_result = pgquery (conn, query_stmt, param)\n",
    "print(query_stmt)\n",
    "pprint.pprint(query_result)\n",
    "\n",
    "# cleanup\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOUR TASK:\n",
    "\n",
    "Run the above SQL examples and then answer the following questions with an SQL query:\n",
    "\n",
    "1.  In which time period were all the measurement done?\n",
    "\n",
    "2.  At how many distinct Stations were used? Which Stations?\n",
    "\n",
    "3.  Do the same statistical analysis for temprature measurements as above, but for just measurements from the year 2005;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: replace the content of this cell with your SQL solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STOP PLEASE. THE FOLLOWING IS FOR THE NEXT EXERCISE. THANKS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE 2: Summarising Data with SQL\n",
    "\n",
    "In the next exercise, we look at the SQL language in a bit more depth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQL: Data Analysis with GROUP BY\n",
    "\n",
    "So far, our aggregate functions were always applied to all tuples in a table.\n",
    "Sometimes it is however very useful to group  rows into distinct partitions and then aggregate for each partition separatly. This is what the **GROUP BY** clause of SQL is doing.\n",
    "\n",
    "**Example 1:**\n",
    "How many measurements were done *per each sensor*?\n",
    "<pre>\n",
    "  SELECT sensor, COUNT(*)\n",
    "    FROM Measurement\n",
    "   GROUP BY sensor;\n",
    "</pre>\n",
    "\n",
    "**Example 2:**\n",
    "How many measurements of *distinct* stations were done *per each sensor*?\n",
    "<pre>\n",
    "SELECT sensor,  COUNT(DISTINCT station)\n",
    "  FROM Measurement\n",
    " GROUP BY sensor\n",
    " ORDER BY count DESC;\n",
    "</pre>\n",
    "<pre>\n",
    "SELECT station, sensor,  COUNT(*)\n",
    "  FROM Measurement \n",
    " GROUP BY station, sensor\n",
    " ORDER BY count DESC;\n",
    "</pre>\n",
    "\n",
    "**Example 3:**\n",
    "Determine some basic statistics about the measured temperature values *per each station*, including minimum temperature, maximum temperature, range of temperature values, mean, mode, 25th and 75th percentile:\n",
    "<pre>\n",
    "SELECT S.SiteName,\n",
    "       MIN(value), \n",
    "       Max(value), \n",
    "       MAX(value) - MIN(value)                           AS Range,\n",
    "       AVG(value)                                            AS Mean,\n",
    "       MODE()  WITHIN GROUP (ORDER BY value)                 AS Mode, \n",
    "       PERCENTILE_DISC(0.5) WITHIN GROUP (ORDER BY value)    AS Median,\n",
    "       PERCENTILE_DISC(0.25) WITHIN GROUP (ORDER BY value)   AS Percentile25,\n",
    "       PERCENTILE_DISC(0.75) WITHIN GROUP (ORDER BY value)   AS Percentile75,\n",
    "       PERCENTILE_DISC(0.75) WITHIN GROUP (ORDER BY value)\n",
    "       - PERCENTILE_DISC(0.25) WITHIN GROUP (ORDER BY value) AS IQR \n",
    "  FROM Measurement M JOIN Station S ON (M.station = S.station)\n",
    "  WHERE sensor ='temp' AND extract(year from date) = 2004\n",
    " GROUP BY S.siteName;\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### YOUR TASK:\n",
    "\n",
    "Answer the following questions with SQL GROUP-BY queries:\n",
    "\n",
    "1. Determine the same per-station statistics as in the last grouping query just for measurements in 2005.\n",
    "\n",
    "2. Same than in (1), but just those values with at least 142 measurements.\n",
    "\n",
    "3. How many Measurement were done in 2004 per sensor?\n",
    "\n",
    "4. In which station were the most measurements done?\n",
    "\n",
    "5. Which sensors were used multiple times in different stations?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: replace the content of this cell with your SQL solution\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STOP PLEASE. THE FOLLOWING IS FOR THE NEXT EXERCISE. THANKS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering Data for Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course you do not need to just print the result of a database operation directly to the screen. Once it is in a variable in your Python program, you can work with it as with any other data which you have loaded, eg. from a CSV file before.\n",
    "\n",
    "**Note** that the data read from the postgresql database differs in its typing from the data we retrieved from CSV files so far using the CSV.DictReader:\n",
    " - SQL returns by default a **list of tuples**, while the data read with the CSV reader is a **list of dictionaries**.\n",
    " - The attributes in the tuples of the SQL result are **typed** according to the SQL schema, while the CSV data is **always strings** and hence needs to be type-converted first.\n",
    " \n",
    "The differences is the addressability of each component - in one case positionally, in the other as key-value pairs, and whether we need further type conversions from strings to numbers, or not. \n",
    "\n",
    "The following code snippet demonstrates these typing differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here the type and content analysed for the SQL query result from above\n",
    "print(\"Analysis of the SQL result types - first whole result, then just first entry:\")\n",
    "print( type(query_result) )\n",
    "print( query_result )\n",
    "print( type(query_result[0]) )\n",
    "print( query_result[0] )\n",
    "print( type(query_result[0][0]) )\n",
    "print( query_result[0][0] )\n",
    "\n",
    "# and now for comaprison the type and values read from the raw CSV file\n",
    "import csv\n",
    "data_measurements = list(csv.DictReader(open('Sensors.csv')))\n",
    "\n",
    "print(\"Analysis of the CSV result types - first whole result, then just first entry:\")\n",
    "print( type(data_measurements) )\n",
    "print(data_measurements)\n",
    "print( type(data_measurements[0]) )\n",
    "print(data_measurements[0])\n",
    "print( type(data_measurements[0]['metric']) )\n",
    "print(data_measurements[0]['metric']) # we need to know the attribute key\n",
    "print(data_measurements[0][0]) # does not work!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can read data from a database also into a dictionary, where the keys of each value will be the attribute names from the database schema. This needs a special kind of SQL cursor, a so-called dictionary cursor, which uses the attribute names from the database schema as column keys. The previusly introduced *pgquery()* function allows to pass a 'returntype' argument with which we can control its return type. It controls just a small code variation in how the query cursor is opened. If you set this parameter value to 'dict', we will get the query result as a Python dictionary (dict) returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to your database\n",
    "conn = pgconnect()\n",
    "    \n",
    "# prepare SQL statement\n",
    "query_stmt =\"\"\"SELECT sensor, COUNT(*)\n",
    "            FROM Measurement\n",
    "               GROUP BY sensor;\"\"\"\n",
    "# execute query and print result\n",
    "query_result = pgquery (conn, query_stmt, None, returntype='dict')\n",
    "print(query_result)\n",
    "for r in query_result:\n",
    "    print(r)\n",
    "# cleanup\n",
    "conn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## EXERCISE 3:  Data Visualisation of Query Results\n",
    "\n",
    "Next we want to do some data visualisation with data read from a SQL database.\n",
    "\n",
    "The **make_plot()** function below will take any query result and turn it into either a simple bar chart, or a scatter plot. Which one you can control with the last 'categorica' argument which schould be True for a bar chart, otherwise false."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def make_plot(data, x_key, y_key, title, xlabel=None, ylabel=None, bar_width=0.5, categorical=True):\n",
    "    xlabel = xlabel or x_key\n",
    "    ylabel = ylabel or y_key\n",
    "    xs = [row[x_key] for row in data]\n",
    "    ys = [row[y_key] for row in data]\n",
    "    \n",
    "    if categorical:\n",
    "        plt.bar(range(len(data)), ys, width=bar_width)\n",
    "        plt.xticks(np.arange(len(data))+bar_width/2., xs)\n",
    "    else:\n",
    "        plt.scatter(xs, ys)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now use this function to plot our previous query result in first a bar chart, and then a scatter plot of the 'sensor' value versus the 'count' ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " # connect to your database\n",
    "conn = pgconnect()\n",
    "    \n",
    "# prepare SQL statement\n",
    "query_stmt =\"\"\"SELECT sensor, COUNT(*)\n",
    "            FROM Measurement\n",
    "               GROUP BY sensor;\"\"\"\n",
    "# execute query and print result\n",
    "query_result = pgquery (conn, query_stmt, None, returntype='dict')\n",
    "print(query_result)\n",
    "for r in query_result:\n",
    "    print(r)\n",
    "# cleanup\n",
    "conn.close()\n",
    "\n",
    "make_plot(\n",
    "    query_result,\n",
    "    x_key='sensor',\n",
    "    y_key='count',\n",
    "    title='Sensor Measurements',\n",
    "    categorical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# connect to your database\n",
    "conn = pgconnect()\n",
    "    \n",
    "# prepare SQL statement\n",
    "query_stmt =\"\"\"SELECT * FROM  Measurement WHERE sensor = 'temp' AND extract(month from date) BETWEEN 4 AND 5 ORDER BY date DESC\"\"\"\n",
    "# execute query and print result\n",
    "query_result = pgquery (conn, query_stmt, None, returntype='dict')\n",
    "print(query_result)\n",
    "\n",
    "# cleanup\n",
    "conn.close()\n",
    "\n",
    "\n",
    "make_plot(\n",
    "    query_result,\n",
    "    x_key='date',\n",
    "    y_key='value',\n",
    "    title='Temp Sensor',\n",
    "    categorical=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The code above assumes that you have the query_result from the previous query in a *dict()* type. However the **make_plot()** function would work with a list of tuples too. In this case, simply provide the positional values of the x- and y-attributes for *x_key* and *y_key* (like for example 0 and 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOUR TASK:\n",
    "\n",
    "Next visualise something more interesting, for example visualise the result of the following sql query:\n",
    "<pre>\n",
    "SELECT sensor, COUNT(DISTINCT station)\n",
    "  FROM Measurement\n",
    " GROUP BY sensor\n",
    " ORDER BY count DESC;\n",
    "</pre>\n",
    "\n",
    "\n",
    "Try out some other code examples that visualises the data read from the SQL database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: replace the content of this cell with your Pythoin+SQL solution\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# That's it for today. THANKS."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "bea42e1b0e07028483ba0ff26b9b4dc4fa162e9d0ccb6b0507d54b9d42d30653"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
