{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data transformation, cleaning and loading with Python\n",
    "\n",
    "## WaterInfo Data Set\n",
    "We are considering a water data set this week about Murray River Basin in NSW. We have made available the content of the Excel workbook as a set of four different CSV files. Please upload those CSV files to Jupyter first. \n",
    "\n",
    "**Important:** Make sure that the naming of all the files is as follows:\n",
    " 1. Measurements.csv\n",
    " 2. Organisations.csv\n",
    " 3. Sensors.csv\n",
    " 4. Stations.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXERCISE 1: Data Loading and Database Creation with Python\n",
    "\n",
    "We continue with the same Python environment: the `DictReader` from the `csv` module which support reading and writing of files in comma-separated values (CSV).\n",
    "\n",
    "Make sure that you have uploaded the 'Organisations.csv' CSV file into Jupyter.\n",
    "We will first load the content of this file into Python with the same  csv.DictReader()  mechanism:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Code': 'DNR',\n",
      " 'Organisation': 'NSW Department of Water and Energy (and predecessors)'}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pprint\n",
    "data_organisations = list(csv.DictReader(open('Organisations.csv')))\n",
    "pprint.pprint(data_organisations[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For larger data sets, the following would normally be executed as a stand alone Python program on a shell.\n",
    "First, you need to establish a connection to the postgresql database. \n",
    "__Please edit the YOUR_DBNAME, YOUR_USERNAME and YOUR_PW variables in the Credentials.json file to match your database login. (Refer to the sample josn file provided)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import json\n",
    "\n",
    "f = open('Credentials.json')\n",
    "db_conn_dict = json.load(f)\n",
    "YOUR_DBNAME =  db_conn_dict['database']\n",
    "YOUR_USERNAME = db_conn_dict['user']\n",
    "YOUR_PW = db_conn_dict['password']\n",
    "\n",
    "def pgconnect():\n",
    "  \n",
    "    try: \n",
    "        conn = psycopg2.connect(host='localhost',\n",
    "                                database=YOUR_DBNAME,\n",
    "                                user=YOUR_USERNAME, \n",
    "                                password=YOUR_PW)\n",
    "        print('connected')\n",
    "    except Exception as e:\n",
    "        print(\"unable to connect to the database\")\n",
    "        print(e)\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to execute some SQL statements against the database. As we will have to do so multiple times, we write a dedicated function for executing an arbitrary SQL statement, where we do not expect any result. This handles then also all failures and using psycopg2's 'with' statements also the transaction processing of the database. Below's code will for example automatically commit our SQL statements, as well as rollback if there was any error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def pgexec( conn, sqlcmd, args, msg, silent=False ):\n",
    "   \"\"\" utility function to execute some SQL statement\n",
    "       can take optional arguments to fill in (dictionary)\n",
    "       error and transaction handling built-in \"\"\"\n",
    "   retval = False\n",
    "   with conn:\n",
    "      with conn.cursor() as cur:\n",
    "         try:\n",
    "            if args is None:\n",
    "               cur.execute(sqlcmd)\n",
    "            else:\n",
    "               cur.execute(sqlcmd, args)\n",
    "            if silent == False: \n",
    "                print(\"success: \" + msg)\n",
    "            retval = True\n",
    "         except Exception as e:\n",
    "            if silent == False: \n",
    "                print(\"db error: \")\n",
    "                print(e)\n",
    "   return retval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load our previous data.\n",
    "Important: whenever you use this approach, make sure that the header line of your CSV file has no spaces in its column titles and also no quotes. Otherwise, the csv.DictReader might be fine to read it, but not the psycopg2's cursor.execute() function. We are using named placeholders in out INSERT statement below (eg. '%(SiteName)s' ) which expects to put a string (%s) into that place of the INSERT statement as been found in the given dictionary for the execute() call with the key 'SiteName'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected\n",
      "db error: \n",
      "cannot drop table organisation because other objects depend on it\n",
      "DETAIL:  constraint orgcodefk on table station depends on table organisation\n",
      "HINT:  Use DROP ... CASCADE to drop the dependent objects too.\n",
      "\n",
      "success: Create Table Organisation\n",
      "db error: \n",
      "column \"orgname\" of relation \"organisation\" does not exist\n",
      "LINE 1: INSERT INTO Organisation(code,orgName) VALUES ('DNR', 'NSW D...\n",
      "                                      ^\n",
      "\n",
      "db error: \n",
      "column \"orgname\" of relation \"organisation\" does not exist\n",
      "LINE 1: INSERT INTO Organisation(code,orgName) VALUES ('DWR', 'NSW D...\n",
      "                                      ^\n",
      "\n",
      "db error: \n",
      "column \"orgname\" of relation \"organisation\" does not exist\n",
      "LINE 1: INSERT INTO Organisation(code,orgName) VALUES ('MIL', 'Murra...\n",
      "                                      ^\n",
      "\n",
      "db error: \n",
      "column \"orgname\" of relation \"organisation\" does not exist\n",
      "LINE 1: INSERT INTO Organisation(code,orgName) VALUES ('PWD', 'Manly...\n",
      "                                      ^\n",
      "\n",
      "db error: \n",
      "column \"orgname\" of relation \"organisation\" does not exist\n",
      "LINE 1: INSERT INTO Organisation(code,orgName) VALUES ('QWR', 'Qld D...\n",
      "                                      ^\n",
      "\n",
      "db error: \n",
      "column \"orgname\" of relation \"organisation\" does not exist\n",
      "LINE 1: INSERT INTO Organisation(code,orgName) VALUES ('SCA', 'Sydne...\n",
      "                                      ^\n",
      "\n",
      "db error: \n",
      "column \"orgname\" of relation \"organisation\" does not exist\n",
      "LINE 1: INSERT INTO Organisation(code,orgName) VALUES ('SMA', 'Snowy...\n",
      "                                      ^\n",
      "\n",
      "db error: \n",
      "column \"orgname\" of relation \"organisation\" does not exist\n",
      "LINE 1: INSERT INTO Organisation(code,orgName) VALUES ('SWB', 'Sydne...\n",
      "                                      ^\n",
      "\n",
      "db error: \n",
      "column \"orgname\" of relation \"organisation\" does not exist\n",
      "LINE 1: INSERT INTO Organisation(code,orgName) VALUES ('VRW', 'Vic G...\n",
      "                                      ^\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1st: login to database\n",
    "conn = pgconnect()\n",
    "\n",
    "# if you want to reset the table\n",
    "pgexec (conn, \"DROP TABLE IF EXISTS Organisation\", None, \"Reset Table Organisation\")\n",
    "\n",
    "# 2nd: ensure that the schema is in place\n",
    "\n",
    "organisation_schema = \"\"\"CREATE TABLE IF NOT EXISTS Organisation (\n",
    "                         code VARCHAR(20) PRIMARY KEY,\n",
    "                         orgName VARCHAR(150)\n",
    "                   )\"\"\"\n",
    "pgexec (conn, organisation_schema, None, \"Create Table Organisation\")\n",
    "\n",
    "# 3nd: load data\n",
    "# IMPORTANT: make sure the header line of CSV is without spaces!\n",
    "insert_stmt = \"\"\"INSERT INTO Organisation(code,orgName) VALUES (%(Code)s, %(Organisation)s)\"\"\"\n",
    "for row in data_organisations:\n",
    "    pgexec (conn, insert_stmt, row, \"row inserted\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's check whether this has all worked fine by querying our PostgreSQL database. To do so, we introduce first another utility function which again encapsulates all error and transaction handling. Then we query the new Organisation table and simply print out all tuples found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def pgquery( conn, sqlcmd, args, silent=False ):\n",
    "   \"\"\" utility function to execute some SQL query statement\n",
    "       can take optional arguments to fill in (dictionary)\n",
    "       will print out on screen the result set of the query\n",
    "       error and transaction handling built-in \"\"\"\n",
    "   retval = False\n",
    "   with conn:\n",
    "      with conn.cursor() as cur:\n",
    "         try:\n",
    "            if args is None:\n",
    "                cur.execute(sqlcmd)\n",
    "            else:\n",
    "                cur.execute(sqlcmd, args)\n",
    "            if silent == False:\n",
    "                for record in cur:\n",
    "                    print(record)\n",
    "            retval = True\n",
    "         except Exception as e:\n",
    "            if silent == False:\n",
    "                print(\"db read error: \")\n",
    "                print(e)\n",
    "   return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * FROM Organisation\n",
      "('DNR', 'NSW Department of Water and Energy (and predecessors)')\n",
      "('DWR', 'NSW Department of Water and Energy (and predecessors)')\n",
      "('MIL', 'Murray Irrigation Ltd')\n",
      "('PWD', 'Manly Hydraulics Laboratory')\n",
      "('QWR', 'Qld Department of Natural Resources and Water')\n",
      "('SCA', 'Sydney Catchment Authority')\n",
      "('SMA', 'Snowy Mountains Authority')\n",
      "('SWB', 'Sydney Catchment Authority')\n",
      "('VRW', 'Vic Government')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# check content of Organisation table\n",
    "query_stmt = \"SELECT * FROM Organisation\"\n",
    "print(query_stmt)\n",
    "pgquery (conn, query_stmt, None)\n",
    "\n",
    "# cleanup...   Needed already?  Better not now... \n",
    "# But keep in mind to close connection eventually!\n",
    "# conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Task: Data Loading\n",
    "\n",
    "Try to create and load the Measurement table.\n",
    "\n",
    "    1.read the Measurements csv file\n",
    "    2. Create a matching 'Measurement' table to hold the CSV data\n",
    "    3. Load the content of the csv file into a local 'data_measurements' dictionary in Python\n",
    "    4. Load the data from the 'data_measurements' dictionary into your PostgreSQL table\n",
    "    5. Query and print its content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9948/1662343507.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# TODO: replace the content of this cell with your Python + psycopg2 solution\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TODO: replace the content of this cell with your Python + psycopg2 solution\n",
    "raise NotImplementedError\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STOP PLEASE. THE FOLLOWING IS FOR THE NEXT EXERCISE. THANKS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE 2: Data Cleaning\n",
    "\n",
    "### Data Cleaning\n",
    "We re-use the clean() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "DEFAULT_VALUE = np.nan\n",
    "\n",
    "def clean(data, column_key, convert_function, default_value):\n",
    "    special_values= {} # no special values yet\n",
    "    for row in data:\n",
    "        old_value = row[column_key]\n",
    "        new_value = default_value\n",
    "        try:\n",
    "            if old_value in special_values.keys():\n",
    "                new_value = special_values[old_value]\n",
    "            else:\n",
    "                new_value = convert_function(old_value)\n",
    "        except (ValueError, TypeError):\n",
    "            print('Replacing {} with {} in column {}'.format(row[column_key], new_value, column_key))\n",
    "        row[column_key] = new_value\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_measurements' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9948/3717414423.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# this conversion strips any leading or trailing spaces from the 'Station' values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mclean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_measurements\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Station'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDEFAULT_VALUE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# the following converts the two measurment  columns to float  values - or NaN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mclean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_measurements\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Discharge'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDEFAULT_VALUE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_measurements' is not defined"
     ]
    }
   ],
   "source": [
    "# this conversion strips any leading or trailing spaces from the 'Station' values\n",
    "clean(data_measurements, 'Station', str.strip, DEFAULT_VALUE)\n",
    "\n",
    "# the following converts the two measurment  columns to float  values - or NaN\n",
    "clean(data_measurements, 'Discharge', float, DEFAULT_VALUE)\n",
    "clean(data_measurements, 'MeanDischarge', float, DEFAULT_VALUE)\n",
    "clean(data_measurements, 'Level', float, DEFAULT_VALUE)\n",
    "clean(data_measurements, 'Temp', float, DEFAULT_VALUE)\n",
    "clean(data_measurements, 'EC', float, DEFAULT_VALUE)\n",
    "\n",
    "##now we insert the  data_measurements into the 'Measurement' table \n",
    "# 1st: login to database\n",
    "if(conn):\n",
    "    conn.close();\n",
    "conn = pgconnect()\n",
    "\n",
    "# 2nd: ensure that the schema is in place\n",
    "pgexec (conn, \"DROP TABLE IF EXISTS Measurement\", None, \"Reset Table Measurement\")\n",
    "measurement_schema = \"\"\"CREATE TABLE IF NOT EXISTS Measurement (\n",
    "                         station   VARCHAR(20),\n",
    "                         date DATE,\n",
    "                         level  FLOAT,\n",
    "                         meanDischarge FLOAT,\n",
    "                         discharge  FLOAT,\n",
    "                         temp FLOAT,\n",
    "                         ec  FLOAT\n",
    "                      )\"\"\"\n",
    "pgexec (conn, measurement_schema, None, \"Create Table Measurement\")\n",
    "\n",
    "# 3nd: load data\n",
    "# IMPORTANT: make sure the header line of CSV is without spaces!\n",
    "insert_stmt = \"\"\"INSERT INTO Measurement(station,date,level,meandischarge,discharge,temp,ec)\n",
    "                      VALUES (%(Station)s, %(Date)s, %(Level)s,%(MeanDischarge)s,%(Discharge)s,%(Temp)s,%(EC)s)\"\"\"\n",
    "for row in data_measurements:\n",
    "    pgexec (conn, insert_stmt, row, \"row inserted\")\n",
    "    \n",
    "query_stmt = \"SELECT COUNT(*) FROM Measurement\"\n",
    "print(query_stmt)\n",
    "pgquery (conn, query_stmt, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Task: Data Cleaning\n",
    "\n",
    "Use above's  clean()  function to clean the other give data set too.\n",
    " 1. read the Stations csv file into data_stations\n",
    " 2. Clean the  'data_stations'  data set\n",
    " 3. Reload the 'data_stations'  dictionary into your database\n",
    " 4. Query the 'Stations' table - which difference do you see?\n",
    " \n",
    " 5. If you have time: Do all of the above (reading - cleaning - loading) also for the 'Sensors.csv' data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: You might encounter a few warning and error messages.\n",
    "   - If a connection is closed, you have to open the databse connection again first\n",
    "   - If the clean() function returns a warning that some string was replaced with NaN, as long as this is indeed a number attribute, you are Ok to ignore this message. It just tells you that it is doing what it is supposed to do.\n",
    "   - If you try to insert data into an already existing table with data inside, you might get 'duplicate primary key' error messages. Again, you can ignore those for the moment.\n",
    "   - If you want to see who much data is already in your table, use the following SQL query:\n",
    "     -  SELECT COUNT(*) FROM Stations;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: replace the content of this cell with your Python solution\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STOP PLEASE. THE FOLLOWING IS FOR THE NEXT EXERCISE. THANKS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE 3: Database Creation\n",
    "After we discussed the model, we will give you an example solution (see below).\n",
    "The next step is to create the corresponding SQL schema in your PostgreSQL database.\n",
    "\n",
    "### Your Task: DB Creation in PostgreSQL\n",
    "Create the corresponding tables in PostgreSQL which follow from the data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "DROP TABLE IF EXISTS Organisation CASCADE;\n",
    "CREATE TABLE IF NOT EXISTS Organisation (\n",
    "   code VARCHAR(20) PRIMARY KEY,\n",
    "   organisation    VARCHAR(150)\n",
    ");\n",
    "\n",
    "DROP TABLE IF EXISTS Station CASCADE;\n",
    "CREATE TABLE IF NOT EXISTS Station (\n",
    "     station   VARCHAR(50) PRIMARY KEY,\n",
    "     siteName  VARCHAR(50),\n",
    "     commence Date,\n",
    "     orgCode  VARCHAR(50),\n",
    "     CONSTRAINT orgCodeFK FOREIGN KEY (orgCode)   REFERENCES Organisation (code)\n",
    " );\n",
    "\n",
    "DROP TABLE IF EXISTS Sensor CASCADE;\n",
    "CREATE TABLE IF NOT EXISTS Sensor (\n",
    "     sensor   VARCHAR(20) PRIMARY KEY,\n",
    "     description  VARCHAR(150) ,       \n",
    "     metric VARCHAR(20)                 \n",
    "  );\n",
    "\n",
    "DROP TABLE IF EXISTS Measurement CASCADE;\n",
    "CREATE TABLE IF NOT EXISTS Measurement (\n",
    "     station   VARCHAR(20),\n",
    "     sensor   VARCHAR(20),\n",
    "     date DATE,\n",
    "     value  FLOAT,\n",
    "     CONSTRAINT stationFK FOREIGN KEY (station)   REFERENCES Station (Station),\n",
    "     CONSTRAINT sensorFK FOREIGN KEY (sensor)   REFERENCES sensor (sensor)\n",
    "  );\n",
    "                      \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: replace the content of this cell with your Python + SQL solution\n",
    "raise NotImplementedError\n",
    "# make sure we are still connected to database \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STOP PLEASE. THE FOLLOWING IS FOR THE NEXT EXERCISE. THANKS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE 4: Data Loading and Storage\n",
    "\n",
    "Up-to this point, we have\n",
    " - analysed and modelled the given data set\n",
    " - created a corresponding relational star schema\n",
    " - read the individual CSV files into Python dictionary data structures\n",
    " - cleaned the raw data with regard to missing or inconsistent entries and data types\n",
    " \n",
    "The final step is to load this cleaned data into the corresponding tables of the star schema which we defined so far.\n",
    "\n",
    "For this to work, you probably will need to write some logic to load different parts of different data dictionaries (holding the content of CSV files) into different tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pprint\n",
    "# Organisation table\n",
    "data_organisations = list(csv.DictReader(open('Organisations.csv')))\n",
    "\n",
    "# make sure we are still connected to database \n",
    "if conn is None or conn.closed:\n",
    "    conn = pgconnect()\n",
    "\n",
    "# check for any existing content of the Organisations table\n",
    "query_stmt = \"SELECT COUNT(*) FROM Organisation\"\n",
    "print(query_stmt)\n",
    "pgquery (conn, query_stmt, None)\n",
    "\n",
    "# Try to load data - 9 tupels should be created\n",
    "insert_stmt = \"\"\"INSERT INTO Organisation(code,organisation) VALUES (%(Code)s, %(Organisation)s)\"\"\"\n",
    "for row in data_organisations:\n",
    "    pgexec (conn, insert_stmt, row, \"row inserted\")\n",
    "    \n",
    "#####################\n",
    "# Station table    \n",
    "data_stations = list(csv.DictReader(open('Stations.csv')))\n",
    "\n",
    "# IMPORTANT: make sure the header line of CSV is without spaces!\n",
    "insert_stmt = \"\"\"INSERT INTO Station(station,siteName,commence,orgCode)\n",
    "                      VALUES (%(station)s, %(siteName)s, %(commence)s,%(orgCode)s)\"\"\"\n",
    "stationData = dict()\n",
    "for row in data_stations:\n",
    "    stationData['station'] = row['BasinNo']+row['Site']\n",
    "    stationData['siteName']  = row['SiteName']\n",
    "    stationData['commence'] = row['Commence']\n",
    "    stationData['orgCode'] = row['OrgCode']\n",
    "    pgexec (conn, insert_stmt, stationData, \"station inserted\")\n",
    "\n",
    "# check content of Station table\n",
    "query_stmt = \"SELECT * FROM Station\"\n",
    "print(query_stmt)\n",
    "pgquery (conn, query_stmt, None)\n",
    "\n",
    "\n",
    "\n",
    "#####################\n",
    "# Sensor table    \n",
    "data_sensors = list(csv.DictReader(open('Sensors.csv')))\n",
    "\n",
    "# IMPORTANT: make sure the header line of CSV is without spaces!\n",
    "insert_stmt = \"\"\"INSERT INTO Sensor(sensor,description,metric)\n",
    "                      VALUES (%(sensor)s, %(description)s, %(metric)s)\"\"\"\n",
    "\n",
    "for row in data_sensors:\n",
    "    pgexec (conn, insert_stmt, row, \"sensor inserted\")\n",
    "\n",
    "# check content of Station table\n",
    "query_stmt = \"SELECT * FROM Sensor\"\n",
    "print(query_stmt)\n",
    "pgquery (conn, query_stmt, None)\n",
    "\n",
    "\n",
    "#####################\n",
    "# Measurement table    \n",
    "data_measurements = list(csv.DictReader(open('Measurements.csv')))\n",
    "\n",
    "# the following converts the two measurment  columns to float  values - or NaN\n",
    "clean(data_measurements, 'Discharge', float, DEFAULT_VALUE)\n",
    "clean(data_measurements, 'MeanDischarge', float, DEFAULT_VALUE)\n",
    "clean(data_measurements, 'Level', float, DEFAULT_VALUE)\n",
    "clean(data_measurements, 'Temp', float, DEFAULT_VALUE)\n",
    "clean(data_measurements, 'EC', float, DEFAULT_VALUE)\n",
    "\n",
    "# IMPORTANT: make sure the header line of CSV is without spaces!\n",
    "insert_stmt = \"\"\"INSERT INTO Measurement(station,date,sensor,value)\n",
    "                      VALUES (%(station)s, %(date)s, %(sensor)s, %(value)s)\"\"\"\n",
    "\n",
    "measurementData = dict()\n",
    "sensorCodes = ['levl', 'disvol','disc','temp', 'ec']\n",
    "sensor_columns = ['Level', 'MeanDischarge', 'Discharge','Temp', 'EC']\n",
    "for row in data_measurements:\n",
    "    measurementData['station'] = row['Station']\n",
    "    measurementData['date'] = row['Date']\n",
    "    for i in range(len(sensorCodes)):\n",
    "        if(np.isnan(row[sensor_columns[i]])):\n",
    "            continue;\n",
    "        measurementData['sensor'] = sensorCodes[i]\n",
    "        measurementData['value']  = row[sensor_columns[i]]\n",
    "        pgexec (conn, insert_stmt, measurementData, \"measurement inserted\")\n",
    "    \n",
    "\n",
    "# check content of Measurement table\n",
    "query_stmt = \"SELECT * FROM Measurement\"\n",
    "print(query_stmt)\n",
    "pgquery (conn, query_stmt, None)\n",
    "\n",
    "query_stmt = \"SELECT count(*) FROM Measurement\"\n",
    "print(query_stmt)\n",
    "pgquery (conn, query_stmt, None)\n",
    "conn.close();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Task: Data Storage in PostgreSQL\n",
    "Following the above pattern, make sure all the   tables of our water schema are loaded with the data from the different CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: replace the content of this cell with your Python + SQL solution\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Exercise. Many Thanks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "f64141119dd496527b87473b8ebe788f11b9494f1fcdf33af43c3720a0f3b587"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
